import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import Ridge
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import pickle
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

print("ğŸš€ MODÃˆLE OPTIMISÃ‰ AVEC LAGS - AMÃ‰LIORATION 33%")
print("=" * 60)

# === 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES ===
print("\nğŸ“Š 1. Chargement et prÃ©paration des donnÃ©es...")

df = pd.read_csv("data_with_context_fixed.csv")
df['Day'] = pd.to_datetime(df['Day'])
df = df.sort_values('Day').reset_index(drop=True)

print(f"ğŸ“Š DonnÃ©es chargÃ©es: {len(df)} jours")

# === 2. DÃ‰TECTION AUTOMATIQUE DES JOURS FÃ‰RIÃ‰S ===
def creer_detecteur_jours_feries(csv_path="data_with_context_fixed.csv"):
    """CrÃ©e un dÃ©tecteur de jours fÃ©riÃ©s basÃ© sur les vraies donnÃ©es historiques"""
    df_temp = pd.read_csv(csv_path)
    df_temp['Day'] = pd.to_datetime(df_temp['Day'])
    
    # Extraire les jours fÃ©riÃ©s rÃ©els
    jours_feries = df_temp[(df_temp['is_holiday_full'] == 1) | (df_temp['is_holiday_half'] == 1)].copy()
    
    # CrÃ©er des patterns rÃ©currents
    patterns_feries = set()
    for _, row in jours_feries.iterrows():
        date = row['Day']
        patterns_feries.add((date.month, date.day))
    
    print(f"ğŸ‰ {len(patterns_feries)} patterns de jours fÃ©riÃ©s dÃ©tectÃ©s")
    
    def detecter_jour_ferie(date):
        return 1 if (date.month, date.day) in patterns_feries else 0
    
    return detecter_jour_ferie, patterns_feries

detecteur_feries, patterns_feries_globaux = creer_detecteur_jours_feries()

# === 3. CRÃ‰ATION DES FEATURES COMPLÃˆTES + LAGS ===
print("\nğŸ”§ 2. CrÃ©ation des features complÃ¨tes + LAGS optimisÃ©s...")

def create_features_avec_lags(df):
    """CrÃ©Ã© des features complÃ¨tes AVEC lags J-1 et J-7"""
    df = df.copy()
    
    # === FEATURES MÃ‰TÃ‰O COMPLÃˆTES ===
    df['temp_range'] = df['TempMax'] - df['TempMin']
    df['temp_ma_7'] = df['TempAvg'].rolling(window=7, min_periods=1).mean()
    df['temp_ma_30'] = df['TempAvg'].rolling(window=30, min_periods=1).mean()
    df['temp_squared'] = df['TempAvg'] ** 2
    
    df['precip_ma_7'] = df['Precip'].rolling(window=7, min_periods=1).mean()
    df['has_rain'] = (df['Precip'] > 0).astype(int)
    
    df['wind_ma_7'] = df['WindSpeed'].rolling(window=7, min_periods=1).mean()
    df['pressure_ma_7'] = df['Pressure'].rolling(window=30, min_periods=1).mean()
    
    # === SEUILS TEMPÃ‰RATURE OPTIMISÃ‰S ===
    temp_25, temp_30 = 25.0, 30.0
    df['cooling_needs_light'] = np.maximum(0, df['TempAvg'] - temp_25)
    df['cooling_needs_heavy'] = np.maximum(0, df['TempAvg'] - temp_30)
    df['heating_needs'] = np.maximum(0, temp_25 - df['TempAvg'])
    
    df['temp_above_25'] = (df['TempAvg'] > 25).astype(int)
    df['temp_above_28'] = (df['TempAvg'] > 28).astype(int)
    df['temp_above_30'] = (df['TempAvg'] > 30).astype(int)
    
    # === SAISONS EXPLICITES ===
    df['is_summer'] = ((df['Day'].dt.month >= 6) & (df['Day'].dt.month <= 8)).astype(int)
    df['is_winter'] = ((df['Day'].dt.month == 12) | (df['Day'].dt.month <= 2)).astype(int)
    df['is_mid_summer'] = (df['Day'].dt.month == 7).astype(int)
    
    # === FEATURES CYCLIQUES ===
    df['month_sin'] = np.sin(2 * np.pi * df['Day'].dt.month / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['Day'].dt.month / 12)
    df['day_of_year_sin'] = np.sin(2 * np.pi * df['Day'].dt.dayofyear / 365)
    df['day_of_year_cos'] = np.cos(2 * np.pi * df['Day'].dt.dayofyear / 365)
    
    # === INTERACTIONS MÃ‰TÃ‰O AVANCÃ‰ES ===
    df['temp_x_summer'] = df['TempAvg'] * df['is_summer']
    df['temp_x_mid_summer'] = df['TempAvg'] * df['is_mid_summer']
    df['temp_squared_x_summer'] = df['temp_squared'] * df['is_summer']
    df['temp_x_wind'] = df['TempAvg'] * df['WindSpeed']
    df['pressure_x_temp'] = df['Pressure'] * df['TempAvg']
    
    # === TEMPOREL ===
    reference_date = pd.to_datetime('2022-01-01')
    df['time_trend'] = (df['Day'] - reference_date).dt.days / 365.25
    df['is_weekend'] = (df['Day'].dt.dayofweek >= 5).astype(int)
    
    # === JOURS FÃ‰RIÃ‰S RÃ‰ELS ===
    vraie_holiday = (df['is_holiday_full'] + df['is_holiday_half'] > 0).astype(int)
    df['is_holiday'] = vraie_holiday
    
    # === ğŸ¯ LAGS CRITIQUES J-1 et J-7 ===
    df['consumption_lag_1'] = df['DailyAverage'].shift(1)
    df['consumption_lag_7'] = df['DailyAverage'].shift(7)
    
    # === FEATURES FIN D'ANNÃ‰E (diagnostic a montrÃ© concentration en dÃ©cembre) ===
    df['is_december'] = (df['Day'].dt.month == 12).astype(int)
    df['days_to_new_year'] = 32 - df['Day'].dt.day  # Distance au nouvel an
    df['is_end_of_year'] = ((df['Day'].dt.month == 12) & (df['Day'].dt.day >= 15)).astype(int)
    
    return df

df_features = create_features_avec_lags(df)

# Supprimer les NaN crÃ©Ã©s par les lags
df_features = df_features.dropna()

print(f"âœ… Features complÃ¨tes crÃ©Ã©es avec lags")
print(f"ğŸ“Š DonnÃ©es aprÃ¨s lags: {len(df_features)} jours")

# === 4. DÃ‰FINITION DES FEATURES OPTIMISÃ‰ES ===
enhanced_features_with_lags = [
    # === TEMPÃ‰RATURE ===
    'TempAvg', 'TempMin', 'TempMax',
    'temp_range', 'temp_ma_7', 'temp_ma_30', 'temp_squared',
    
    # === PRÃ‰CIPITATIONS ===
    'Precip', 'precip_ma_7', 'has_rain',
    
    # === VENT ET PRESSION ===
    'WindSpeed', 'wind_ma_7', 'Pressure', 'pressure_ma_7',
    
    # === SEUILS TEMPÃ‰RATURE ===
    'cooling_needs_light', 'cooling_needs_heavy', 'heating_needs',
    'temp_above_25', 'temp_above_28', 'temp_above_30',
    
    # === SAISONS ===
    'is_summer', 'is_winter', 'is_mid_summer',
    'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos',
    
    # === INTERACTIONS AVANCÃ‰ES ===
    'temp_x_summer', 'temp_x_mid_summer', 'temp_squared_x_summer',
    'temp_x_wind', 'pressure_x_temp',
    
    # === TEMPOREL ===
    'time_trend', 'is_weekend', 'is_holiday',
    
    # === ğŸ¯ LAGS CRITIQUES (GAIN 33%) ===
    'consumption_lag_1', 'consumption_lag_7',
    
    # === FEATURES FIN D'ANNÃ‰E ===
    'is_december', 'days_to_new_year', 'is_end_of_year'
]

print(f"ğŸ¯ {len(enhanced_features_with_lags)} features avec lags optimisÃ©s")

# === 5. SPLIT TEMPOREL PROPRE ===
print("\nğŸ“… 3. Split temporel optimisÃ©...")

split_idx = int(len(df_features) * 0.7)
train_data = df_features.iloc[:split_idx].copy()
test_data = df_features.iloc[split_idx:].copy()

print(f"ğŸ“Š Split temporel:")
print(f"   Train: {train_data['Day'].min().date()} â†’ {train_data['Day'].max().date()} ({len(train_data)} jours)")
print(f"   Test:  {test_data['Day'].min().date()} â†’ {test_data['Day'].max().date()} ({len(test_data)} jours)")

# PrÃ©parer les donnÃ©es
X_train = train_data[enhanced_features_with_lags]
X_test = test_data[enhanced_features_with_lags]
y_train = train_data['DailyAverage'].values
y_test = test_data['DailyAverage'].values

# === 6. NORMALISATION ===
print("\nğŸ“ 4. Normalisation...")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# === 7. ENTRAÃNEMENT MODÃˆLE OPTIMISÃ‰ ===
print("\nğŸ¤– 5. EntraÃ®nement modÃ¨le Ridge optimisÃ© (Î±=10.0)...")

# Utiliser le meilleur Î± trouvÃ© par le diagnostic
model_optimise = Ridge(alpha=10.0, random_state=42)
model_optimise.fit(X_train_scaled, y_train)

# === 8. PRÃ‰DICTIONS ET Ã‰VALUATION ===
print("\nğŸ“Š 6. Ã‰valuation du modÃ¨le optimisÃ©...")

train_pred = model_optimise.predict(X_train_scaled)
test_pred = model_optimise.predict(X_test_scaled)

# MÃ©triques
train_mae = mean_absolute_error(y_train, train_pred)
test_mae = mean_absolute_error(y_test, test_pred)
train_r2 = r2_score(y_train, train_pred)
test_r2 = r2_score(y_test, test_pred)

print(f"ğŸ¯ PERFORMANCE MODÃˆLE OPTIMISÃ‰:")
print(f"   Train - MAE: {train_mae:.0f} kWh, RÂ²: {train_r2:.3f}")
print(f"   Test  - MAE: {test_mae:.0f} kWh, RÂ²: {test_r2:.3f}")
print(f"   Overfitting: {train_r2 - test_r2:.3f}")

# === 9. IMPORTANCE DES FEATURES ===
print("\nğŸ”¥ 7. Importance des features (Ridge coefficients)...")

feature_importance = np.abs(model_optimise.coef_)
feature_names = enhanced_features_with_lags

importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

print(f"\nğŸ† TOP 15 FEATURES IMPORTANTES:")
for i, (_, row) in enumerate(importance_df.head(15).iterrows()):
    print(f"   {i+1:2d}. {row['feature']:<25}: {row['importance']:.3f}")

# === 10. SAUVEGARDE DU MODÃˆLE OPTIMISÃ‰ ===
print("\nğŸ’¾ 8. Sauvegarde du modÃ¨le optimisÃ©...")

model_data_optimise = {
    'model': model_optimise,
    'scaler': scaler,
    'features': enhanced_features_with_lags,
    'patterns_feries': patterns_feries_globaux,  # Seulement les patterns, pas la fonction
    'performance': {
        'train_mae': train_mae,
        'test_mae': test_mae,
        'train_r2': train_r2,
        'test_r2': test_r2,
        'overfitting': train_r2 - test_r2
    },
    'version': 'optimise_avec_lags_v1.0',
    'date_creation': datetime.now(),
    'nb_features': len(enhanced_features_with_lags)
}

with open('modele_optimise_avec_lags.pkl', 'wb') as f:
    pickle.dump(model_data_optimise, f)

print(f"âœ… ModÃ¨le sauvegardÃ©: modele_optimise_avec_lags.pkl")

# === 11. VISUALISATIONS DE VALIDATION ===
print("\nğŸ“Š 9. GÃ©nÃ©ration des visualisations...")

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('ğŸš€ MODÃˆLE OPTIMISÃ‰ AVEC LAGS - VALIDATION', fontsize=16, fontweight='bold')

# Plot 1: PrÃ©dictions vs RÃ©el (Test)
axes[0,0].scatter(y_test, test_pred, alpha=0.6, color='orange', s=20)
axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)
axes[0,0].set_xlabel('Consommation RÃ©elle (kWh)')
axes[0,0].set_ylabel('Consommation PrÃ©dite (kWh)')
axes[0,0].set_title(f'Test: PrÃ©dictions vs RÃ©el (RÂ²={test_r2:.3f})')
axes[0,0].grid(True, alpha=0.3)

# Plot 2: RÃ©sidus vs TempÃ©rature (vÃ©rifier S-curve)
test_residuals = y_test - test_pred
axes[0,1].scatter(test_data['TempAvg'], test_residuals, alpha=0.6, color='green', s=20)
axes[0,1].axhline(y=0, color='red', linestyle='--', alpha=0.7)
axes[0,1].set_xlabel('TempÃ©rature Moyenne (Â°C)')
axes[0,1].set_ylabel('RÃ©sidus (kWh)')
axes[0,1].set_title('RÃ©sidus vs TempÃ©rature (S-curve corrigÃ©e)')
axes[0,1].grid(True, alpha=0.3)

# Plot 3: Ã‰volution temporelle des erreurs
axes[1,0].plot(test_data['Day'], np.abs(test_residuals), color='purple', alpha=0.7, linewidth=1)
axes[1,0].axhline(y=test_mae, color='red', linestyle='--', label=f'MAE moyen: {test_mae:.0f} kWh')
axes[1,0].set_xlabel('Date')
axes[1,0].set_ylabel('Erreur Absolue (kWh)')
axes[1,0].set_title('Ã‰volution Temporelle des Erreurs')
axes[1,0].legend()
axes[1,0].grid(True, alpha=0.3)
axes[1,0].tick_params(axis='x', rotation=45)

# Plot 4: Top 10 Features
top_features = importance_df.head(10)
axes[1,1].barh(range(len(top_features)), top_features['importance'].values)
axes[1,1].set_yticks(range(len(top_features)))
axes[1,1].set_yticklabels(top_features['feature'].values)
axes[1,1].set_xlabel('Importance (|coefficient|)')
axes[1,1].set_title('Top 10 Features Importantes')
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('modele_optimise_avec_lags_validation.png', dpi=300, bbox_inches='tight')
plt.show()

# === 12. COMPARAISON AVEC MODÃˆLE PRÃ‰CÃ‰DENT ===
print("\nğŸ“ˆ 10. Comparaison avec le modÃ¨le prÃ©cÃ©dent...")

# Simuler performance du modÃ¨le sans lags (diagnostic)
mae_sans_lags = 5774  # Du diagnostic
improvement = ((mae_sans_lags - test_mae) / mae_sans_lags) * 100

print(f"ğŸ† AMÃ‰LIORATION CONFIRMÃ‰E:")
print(f"   ModÃ¨le sans lags: {mae_sans_lags:.0f} kWh MAE")
print(f"   ModÃ¨le avec lags: {test_mae:.0f} kWh MAE")
print(f"   Gain: {improvement:.1f}% d'amÃ©lioration !")

# === 13. DÃ‰TECTION DES POINTS D'AMÃ‰LIORATION RESTANTS ===
print("\nğŸ” 11. Analyse des erreurs rÃ©siduelles...")

# Erreurs par quartile
quartiles = pd.qcut(y_test, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])
erreur_par_quartile = pd.DataFrame({
    'quartile': quartiles,
    'erreur_relative': np.abs(test_residuals) / y_test
}).groupby('quartile')['erreur_relative'].mean() * 100

print(f"ğŸ“Š Erreur relative par quartile (modÃ¨le optimisÃ©):")
for q, err in erreur_par_quartile.items():
    print(f"   {q}: {err:.1f}%")

# Top 5 pires jours restants
test_errors = test_data.copy()
test_errors['abs_error'] = np.abs(test_residuals)
worst_5 = test_errors.nlargest(5, 'abs_error')

print(f"\nğŸ¯ Top 5 pires jours restants:")
for _, row in worst_5.iterrows():
    print(f"   {row['Day'].strftime('%Y-%m-%d')}: {row['abs_error']:.0f} kWh (Temp: {row['TempAvg']:.1f}Â°C)")

print("\n" + "="*70)
print("ğŸš€ MODÃˆLE OPTIMISÃ‰ AVEC LAGS TERMINÃ‰ !")
print("="*70)
print(f"ğŸ“Š Performance finale: MAE {test_mae:.0f} kWh (RÂ² {test_r2:.3f})")
print(f"ğŸ¯ AmÃ©lioration: {improvement:.1f}% vs modÃ¨le prÃ©cÃ©dent")
print(f"ğŸ’¾ Fichier sauvegardÃ©: modele_optimise_avec_lags.pkl")
print(f"ğŸ“ˆ Graphiques: modele_optimise_avec_lags_validation.png")
print("="*70) 