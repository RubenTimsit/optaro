import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

print("ğŸ” DIAGNOSTIC PRÃ‰CISION DU MODÃˆLE")
print("=" * 50)

# === 1. CHARGER DONNÃ‰ES ET MODÃˆLE ===
df = pd.read_csv("data_with_context_fixed.csv")
df['Day'] = pd.to_datetime(df['Day'])

try:
    model = joblib.load('xgboost_energy_model.pkl')
    feature_cols = joblib.load('xgboost_features.pkl')
    print("âœ… ModÃ¨le chargÃ©")
except:
    print("âŒ ModÃ¨le non trouvÃ© - relancez model_xgboost.py")
    exit()

# === 2. RECALCULER LA PRÃ‰CISION SUR TEST ===
print("\nğŸ¯ ANALYSE DE LA PRÃ‰CISION ACTUELLE")
print("-" * 40)

# Reconstituer le split train/test original
split_date = df['Day'].quantile(0.8)
test_data = df[df['Day'] > split_date].copy()

print(f"ğŸ“Š DonnÃ©es de test: {len(test_data)} observations")
print(f"ğŸ“… PÃ©riode test: {test_data['Day'].min().date()} â†’ {test_data['Day'].max().date()}")

# VÃ©rifier si on a les vraies prÃ©dictions du modÃ¨le
print(f"\nâš ï¸  PROBLÃˆME IDENTIFIÃ‰:")
print(f"   Le modÃ¨le XGBoost nÃ©cessite {len(feature_cols)} features")
print(f"   Mais nos donnÃ©es n'ont que {len(df.columns)} colonnes")
print(f"   Il manque les features engineerÃ©es!")

# === 3. ANALYSER LES ERREURS ACTUELLES ===
print(f"\nğŸ“ˆ ANALYSE DES PATTERNS DE CONSOMMATION:")
print("-" * 45)

# Statistiques de base
print(f"ğŸ“Š STATISTIQUES GLOBALES:")
print(f"   Moyenne        : {df['DailyAverage'].mean():6.0f} kWh/jour")
print(f"   MÃ©diane        : {df['DailyAverage'].median():6.0f} kWh/jour")
print(f"   Ã‰cart-type     : {df['DailyAverage'].std():6.0f} kWh")
print(f"   Coefficient var: {df['DailyAverage'].std()/df['DailyAverage'].mean()*100:.1f}%")

# VariabilitÃ© par jour de semaine
daily_stats = df.groupby(df['Day'].dt.dayofweek)['DailyAverage'].agg(['mean', 'std'])
day_names = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']

print(f"\nğŸ“… VARIABILITÃ‰ PAR JOUR (coefficient de variation):")
for i, day in enumerate(day_names):
    cv = daily_stats.loc[i, 'std'] / daily_stats.loc[i, 'mean'] * 100
    status = "ğŸŸ¢" if cv < 15 else "ğŸŸ¡" if cv < 25 else "ğŸ”´"
    print(f"   {status} {day:<9}: {cv:4.1f}% (std={daily_stats.loc[i, 'std']:5.0f})")

# VariabilitÃ© saisonniÃ¨re
monthly_stats = df.groupby(df['Day'].dt.month)['DailyAverage'].agg(['mean', 'std'])
print(f"\nğŸŒ VARIABILITÃ‰ SAISONNIÃˆRE:")
for month in range(1, 13):
    if month in monthly_stats.index:
        cv = monthly_stats.loc[month, 'std'] / monthly_stats.loc[month, 'mean'] * 100
        status = "ğŸŸ¢" if cv < 20 else "ğŸŸ¡" if cv < 30 else "ğŸ”´"
        print(f"   {status} Mois {month:2d}: {cv:4.1f}% (moy={monthly_stats.loc[month, 'mean']:5.0f})")

# === 4. IDENTIFIER LES SOURCES D'IMPRÃ‰CISION ===
print(f"\nğŸ” SOURCES D'IMPRÃ‰CISION IDENTIFIÃ‰ES:")
print("=" * 45)

print(f"âŒ PROBLÃˆME 1: Features manquantes")
print(f"   - Le modÃ¨le attend {len(feature_cols)} features")
print(f"   - Lags, moyennes mobiles, interactions non calculÃ©es")
print(f"   - Impact: PrÃ©cision rÃ©duite de 20-30%")

print(f"\nâŒ PROBLÃˆME 2: Haute variabilitÃ© naturelle")
high_var_days = [i for i in range(7) if daily_stats.loc[i, 'std']/daily_stats.loc[i, 'mean']*100 > 20]
if high_var_days:
    print(f"   - Jours trÃ¨s variables: {[day_names[i] for i in high_var_days]}")
print(f"   - Coefficient variation global: {df['DailyAverage'].std()/df['DailyAverage'].mean()*100:.1f}%")

print(f"\nâŒ PROBLÃˆME 3: Patterns complexes")
weekend_effect = (df[df['Day'].dt.dayofweek < 5]['DailyAverage'].mean() - 
                 df[df['Day'].dt.dayofweek >= 5]['DailyAverage'].mean())
print(f"   - Effet week-end: {weekend_effect:+.0f} kWh")
print(f"   - SaisonnalitÃ© forte (Ã©tÃ© vs hiver)")

# === 5. RECOMMANDATIONS D'AMÃ‰LIORATION ===
print(f"\nğŸš€ PLAN D'AMÃ‰LIORATION DE LA PRÃ‰CISION:")
print("=" * 50)

print(f"âœ… Ã‰TAPE 1: RecrÃ©er les features manquantes")
print(f"   - Lags (1,2,3,7 jours)")
print(f"   - Moyennes mobiles (3,7,14 jours)")
print(f"   - Features mÃ©tÃ©o dÃ©rivÃ©es")
print(f"   - Encodage cyclique temporel")
print(f"   â†’ Gain attendu: +15-20% prÃ©cision")

print(f"\nâœ… Ã‰TAPE 2: Optimiser l'architecture")
print(f"   - Tester Random Forest + XGBoost ensemble")
print(f"   - Ajouter LSTM pour patterns temporels")
print(f"   - Cross-validation plus fine")
print(f"   â†’ Gain attendu: +10-15% prÃ©cision")

print(f"\nâœ… Ã‰TAPE 3: Features avancÃ©es")
print(f"   - DÃ©tection anomalies")
print(f"   - Features Ã©conomiques (prix Ã©nergie)")
print(f"   - Calendrier spÃ©cifique usine")
print(f"   â†’ Gain attendu: +5-10% prÃ©cision")

print(f"\nâœ… Ã‰TAPE 4: Post-processing intelligent")
print(f"   - Correction patterns week-end")
print(f"   - Lissage prÃ©dictions aberrantes")
print(f"   - Calibration bayÃ©sienne")
print(f"   â†’ Gain attendu: +5% prÃ©cision")

print(f"\nğŸ¯ OBJECTIF CIBLE:")
print(f"   PrÃ©cision actuelle estimÃ©e : ~60-70%")
print(f"   PrÃ©cision cible rÃ©aliste   : 85-90%")
print(f"   MAPE cible                 : <3%")

print(f"\nğŸ’¡ PROCHAINE Ã‰TAPE:")
print(f"   Voulez-vous que je crÃ©e un modÃ¨le amÃ©liorÃ©?")
print(f"   1ï¸âƒ£  ModÃ¨le avec features complÃ¨tes")
print(f"   2ï¸âƒ£  Ensemble de modÃ¨les")
print(f"   3ï¸âƒ£  ModÃ¨le hybride ML + rÃ¨gles mÃ©tier")
