import pandas as pd

# === Configuration ===
INPUT_FILE = "data_7_years.csv"
OUTPUT_FILE = "data_cleaned.csv"

# === Ã‰tape 1 â€“ Charger les donnÃ©es ===
df = pd.read_csv(INPUT_FILE)
print(f"ðŸ“¥ DonnÃ©es chargÃ©es depuis : {INPUT_FILE}")
print(f"Nombre de lignes brutes : {len(df)}")

# === Ã‰tape 2 â€“ Conversion de la date ===
df["Day"] = pd.to_datetime(df["Day"], errors="coerce")

# === Ã‰tape 3 â€“ Tri par SourceID et date ===
df.sort_values(["SourceID", "Day"], inplace=True)

# === Ã‰tape 4 â€“ Suppression des doublons ===
df.drop_duplicates(inplace=True)

# === Ã‰tape 5 â€“ Valeurs manquantes ===
missing = df.isnull().sum()
print("\nðŸ”Ž Valeurs manquantes par colonne :\n", missing)

# On supprime les lignes oÃ¹ la date ou la consommation est manquante
df.dropna(subset=["Day", "DailyAverage", "SourceID"], inplace=True)

# === Ã‰tape 6 â€“ Nettoyage des valeurs aberrantes ===
# On Ã©limine les valeurs nÃ©gatives et trÃ¨s extrÃªmes (> 10 000 000)
df = df[df["DailyAverage"] >= 0]
df = df[df["DailyAverage"] < 1e7]  # seuil Ã  ajuster si besoin

# === Ã‰tape 7 â€“ Statistiques utiles ===
print("\nðŸ“Š Statistiques aprÃ¨s nettoyage :")
print(f"PÃ©riode couverte : {df['Day'].min().date()} â†’ {df['Day'].max().date()}")
print(f"Nombre de SourceID uniques : {df['SourceID'].nunique()}")
print(f"Nombre de lignes finales : {len(df)}")

# === Ã‰tape 8 â€“ Sauvegarde ===
df.to_csv(OUTPUT_FILE, index=False)
print(f"\nâœ… DonnÃ©es nettoyÃ©es sauvegardÃ©es dans : {OUTPUT_FILE}")
print(df.head())
